% TODO : Quellenangaben für absatz?
% Die Integration generativer Künstlicher Intelligenz (KI) in die
% Softwareentwicklung beruht maßgeblich auf dem Einsatz fortschrittlicher Modelle
% und Algorithmen. Insbesondere Large Language Models (LLMs) und
% Transformer-Architekturen bilden die technologische Grundlage moderner
% Coding-Tools wie GitHub Copilot, Cursor oder v0. Im Folgenden werden zentrale
% Modelle, deren Funktionsweise und Bedeutung für typische Entwicklungsaufgaben
% dargestellt.

\label{sec:wichtige-algorithmen-modelle}

Aktuelle Forschung betont, dass ein zukunftsorientiertes Software-Ökosystem
nicht nur technologische Innovation, sondern auch eine optimierte
Zusammenarbeit von Mensch und KI erfordert. Ein systematischer Umgang mit
technischer Verschuldung sowie die gezielte Nutzung externer Wissensquellen
gelten als Schlüsselfaktoren moderner Entwicklungsframeworks
\cite{matsumoto_conceptual_2021}. Darüber hinaus zeigen empirische Studien,
dass KI-Assistenzsysteme die Codequalität und Wartbarkeit nachweislich
verbessern können \cite{martinovic_impact_2024}. Der Ansatz des sogenannten
\glqq AI-Native Software Engineering\grqq{} (SE 3.0) fokussiert eine enge
Verzahnung von KI, Entwicklerkompetenz und Geschäftsprozessen und steht für
einen Wandel hin zu einer kooperativen, dialogorientierten Softwareentwicklung
\cite{hassan_towards_2024}.

Im Kern basieren moderne KI-Tools wie GitHub Copilot, Cursor oder Bolt auf
sogenannten Large Language Models (LLMs) und verwandten Architekturen wie
Transformers. Diese tiefenlernenden neuronalen Netze werden auf großen Mengen
an Quellcode und natürlicher Sprache trainiert und nutzen Mechanismen wie
Self-Attention, um den Kontext über längere Sequenzen hinweg zu erfassen. So
gelingt es den Modellen, sowohl syntaktisch als auch semantisch komplexe
Strukturen zu erkennen und zu generieren, etwa im Bereich der Code-Logik oder
bei der Anwendung typischer Designmuster \cite{nguyen-duc_generative_2023,
    esposito_generative_2025}. Während Diffusionsmodelle in der Bild- und
Mediengenerierung dominieren, bleiben für text- und codebasierte
Softwareentwicklung weiterhin LLMs und Transformer-Architekturen zentral
\cite{weisz_design_2024}.

In der praktischen Anwendung nutzen moderne Assistenzsysteme typischerweise
spezialisierte Sprachmodelle wie OpenAI Codex, Code Llama oder StarCoder, die
gezielt auf Programmcode vortrainiert wurden. Diese Modelle sind in der Lage,
ausgehend vom Kontext, etwa bestehender Code, Kommentare oder Projekthistorie,
automatisiert neue Code-Abschnitte zu generieren, Fehlerkorrekturen
vorzuschlagen oder passende Testfälle zu erstellen \cite{coutinho_role_2024,
    esposito_generative_2025}. Ihr Funktionsspektrum reicht von der automatischen
Erstellung kompletter Funktionen und Module auf Basis kurzer Beschreibungen in
natürlicher Sprache über die Generierung von Unit-Tests und die Unterstützung
beim Review bis hin zur Entwicklung und Auswahl geeigneter
Softwarearchitekturen oder Design Patterns, insbesondere im projektspezifischen
Kontext \cite{coutinho_role_2024, esposito_generative_2025, donvir_role_2024}.

LLMs übernehmen damit zunehmend Aufgaben, die von der reinen Code-Generierung
bis hin zu komplexeren Anforderungen reichen. Sie erstellen automatisiert
Tests, variieren Testdaten, erkennen typische Fehlerbilder und unterstützen
Entwickler:innen durch Vorschläge zur Architektur oder durch das Übersetzen von
Requirements in konkrete Design-Entwürfe oder Diagramme
\cite{esposito_generative_2025, nguyen-duc_generative_2023}.

Trotz des enormen Potenzials solcher Modelle sind wesentliche Herausforderungen
zu beachten. So können LLMs zwar häufig syntaktisch korrekten Code generieren,
dieser ist jedoch nicht immer inhaltlich passend oder sicher, insbesondere bei
vagen Prompts oder fehlendem Kontext (\textit{Halluzinationen}). Die
Erklärbarkeit und Transparenz der generierten Vorschläge bleibt oftmals
eingeschränkt, da die Entscheidungswege der Modelle schwer nachvollziehbar
sind. Ohne gezieltes Fine-Tuning auf spezifische Projekte oder Domänen bleibt
das Wissen zudem meist allgemein und kann individuellen Anforderungen nicht
immer gerecht werden \cite{esposito_generative_2025,
    nguyen-duc_generative_2023, donvir_role_2024}.

Im Praxisteil dieser Arbeit werden die beschriebenen Modelle durch Tools wie
GitHub Copilot, Cursor und Bolt eingesetzt, um Entwickler:innen in sämtlichen
Phasen der Softwareentwicklung, von Architekturentwurf bis Testing, aktiv zu
unterstützen. Diese Werkzeuge etablieren sich damit zunehmend als kollaborative
Partner und verändern klassische Entwicklungsprozesse nachhaltig
\cite{esposito_generative_2025, nguyen-duc_generative_2023}.

